{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*-coding:utf-8\n",
    "'''\n",
    "Created on Fri Dec 1 22:22:35 2017\n",
    "\n",
    "@author: Ray\n",
    "\n",
    "'''\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from glob import glob\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_multiple_csv(path, col = None):\n",
    "\n",
    "    # glob(path+'/*'): return a list, which consist of each files in path\n",
    "\n",
    "    if col is None:\n",
    "        df = pd.concat([pd.read_csv(f) for f in tqdm(sorted(glob(path+'/*')))])\n",
    "    else:\n",
    "        df = pd.concat([pd.read_csv(f)[col] for f in tqdm(sorted(glob(path+'/*')))])\n",
    "    return df\n",
    "def load_pred_feature(name, keep_all = False):\n",
    "    \n",
    "    if keep_all == False:\n",
    "        #==============================================================================\n",
    "        print('keep top imp')\n",
    "        #==============================================================================\n",
    "        col = keep_top_item()\n",
    "        if name=='test':\n",
    "            col.remove('is_churn') # feature中沒有is_churn\n",
    "        df = read_multiple_csv('../feature/{}/all'.format(name), col)\n",
    "        #df = read_multiple_csv('../feature/{}/all_sampling_for_developing'.format(name).format(name), col)\n",
    "    else:\n",
    "        #path = '../feature/{}/all_sampling_for_developing'.format(name)\n",
    "        df = read_multiple_csv('../feature/{}/all'.format(name)) \n",
    "    \n",
    "    print('{}.shape:{}\\n'.format(name, df.shape))\n",
    "    \n",
    "    return df\n",
    "def split_build_valid(valid_size = 0.05):\n",
    "    # train/val split by user(making sure label distribution of training set is nearly same as validating set)\n",
    "    train_user['is_valid'] = np.random.choice([0,1], size=len(train_user), \n",
    "                                              p=[1-valid_size, valid_size]) # randomly pick someone as validation user\n",
    "    # is_valid: 1 if the user is validating user else 0\n",
    "    valid_n = train_user['is_valid'].sum()\n",
    "    build_n = (train_user.shape[0] - valid_n)\n",
    "    print('build user:{}, valid user:{}'.format(build_n, valid_n))\n",
    "    valid_user = train_user[train_user['is_valid']==1].msno\n",
    "    is_valid = X_train.msno.isin(valid_user)\n",
    "    # to create the XGBoost matrices that will be used to train the model using XGBoost. \n",
    "    x_train = X_train[~is_valid].drop('msno', axis=1)\n",
    "    y_train = Y_train[~is_valid]\n",
    "    x_val = X_train[is_valid].drop('msno', axis=1)\n",
    "    y_val = Y_train[is_valid]\n",
    "    print('FINAL SHAPE')\n",
    "    print('x_train.shape:{0}'.format(x_train.shape))\n",
    "    print('x_val.shape:{0}'.format(x_val.shape))\n",
    "\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:53<00:00,  5.70s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainW-0.shape:(881896, 653)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:54<00:00,  5.71s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainW-1.shape:(884309, 653)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:59<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainW-2.shape:(905872, 653)\n",
      "\n",
      "per_churned_in_train_0 0.0587484238504\n",
      "n_churned 10042\n",
      "per_churned_in_train_1 0.0554877139084\n",
      "per_churned_in_train_2 0.0554877139084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 72\n",
    "#==============================================================================\n",
    "# prepare\n",
    "#==============================================================================\n",
    "# load dataset\n",
    "train_0 = load_pred_feature('trainW-0', keep_all = True)\n",
    "train_1 = load_pred_feature('trainW-1', keep_all = True)\n",
    "train_2 = load_pred_feature('trainW-2', keep_all = True)\n",
    "# make data augmentation having same label distribution with training set provided by the kkbox\n",
    "per_churned_in_train_0 = train_0[['is_churn']].describe().ix['mean'][0] \n",
    "n_churned = train_1[train_1.is_churn == 0].shape[0] * per_churned_in_train_0\n",
    "print('per_churned_in_train_0', per_churned_in_train_0)\n",
    "print('n_churned', int(n_churned))\n",
    "train_1 = pd.concat([train_1[train_1.is_churn == 0],\n",
    "                train_1[train_1.is_churn == 1].sample(n = int(n_churned), random_state = seed)\n",
    "               ], ignore_index=True)\n",
    "per_churned_in_train_1 = train_1[['is_churn']].describe().ix['mean'][0] \n",
    "print('per_churned_in_train_1', per_churned_in_train_1)\n",
    "train_2 = pd.concat([train_2[train_2.is_churn == 0],\n",
    "                train_2[train_2.is_churn == 1].sample(n = int(n_churned), random_state = seed)\n",
    "               ], ignore_index=True)\n",
    "per_churned_in_train_2 = train_1[['is_churn']].describe().ix['mean'][0] \n",
    "print('per_churned_in_train_2', per_churned_in_train_2)\n",
    "train = pd.concat([train_0, train_1, train_2], ignore_index=True)\n",
    "del train_0, train_1, train_2\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train['is_churn'] \n",
    "X_train = train.drop('is_churn', axis=1)\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1130966, 652)\n",
      "(1130966,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train/val splitting by user\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# SPLIT!\n",
    "print(' train/val splitting by user')\n",
    "#==============================================================================\n",
    "train_user = X_train[['msno']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. way of itterating through model parameters to tweak the model- manual work(manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build user:837681, valid user:44215\n",
      "FINAL SHAPE\n",
      "x_train.shape:(837681, 651)\n",
      "x_val.shape:(44215, 651)\n",
      "[0]\tvalidation_0-logloss:0.611494\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.544668\n",
      "[2]\tvalidation_0-logloss:0.489123\n",
      "[3]\tvalidation_0-logloss:0.442383\n",
      "[4]\tvalidation_0-logloss:0.402634\n",
      "[5]\tvalidation_0-logloss:0.368629\n",
      "[6]\tvalidation_0-logloss:0.339377\n",
      "[7]\tvalidation_0-logloss:0.314041\n",
      "[8]\tvalidation_0-logloss:0.29209\n",
      "[9]\tvalidation_0-logloss:0.272989\n",
      "[10]\tvalidation_0-logloss:0.256326\n",
      "[11]\tvalidation_0-logloss:0.241791\n",
      "[12]\tvalidation_0-logloss:0.229029\n",
      "[13]\tvalidation_0-logloss:0.217856\n",
      "[14]\tvalidation_0-logloss:0.208076\n",
      "[15]\tvalidation_0-logloss:0.199516\n",
      "[16]\tvalidation_0-logloss:0.192003\n",
      "[17]\tvalidation_0-logloss:0.185384\n",
      "[18]\tvalidation_0-logloss:0.179597\n",
      "[19]\tvalidation_0-logloss:0.174532\n",
      "[20]\tvalidation_0-logloss:0.170066\n",
      "[21]\tvalidation_0-logloss:0.16607\n",
      "[22]\tvalidation_0-logloss:0.162596\n",
      "[23]\tvalidation_0-logloss:0.159579\n",
      "[24]\tvalidation_0-logloss:0.156693\n",
      "[25]\tvalidation_0-logloss:0.154251\n",
      "[26]\tvalidation_0-logloss:0.152024\n",
      "[27]\tvalidation_0-logloss:0.150131\n",
      "[28]\tvalidation_0-logloss:0.148336\n",
      "[29]\tvalidation_0-logloss:0.146787\n",
      "[30]\tvalidation_0-logloss:0.145377\n",
      "[31]\tvalidation_0-logloss:0.144135\n",
      "[32]\tvalidation_0-logloss:0.143085\n",
      "[33]\tvalidation_0-logloss:0.142136\n",
      "[34]\tvalidation_0-logloss:0.141291\n",
      "[35]\tvalidation_0-logloss:0.140548\n",
      "[36]\tvalidation_0-logloss:0.139888\n",
      "[37]\tvalidation_0-logloss:0.139355\n",
      "[38]\tvalidation_0-logloss:0.138798\n",
      "[39]\tvalidation_0-logloss:0.138352\n",
      "[40]\tvalidation_0-logloss:0.137946\n",
      "[41]\tvalidation_0-logloss:0.137597\n",
      "[42]\tvalidation_0-logloss:0.137255\n",
      "[43]\tvalidation_0-logloss:0.136994\n",
      "[44]\tvalidation_0-logloss:0.136723\n",
      "[45]\tvalidation_0-logloss:0.136486\n",
      "[46]\tvalidation_0-logloss:0.136297\n",
      "[47]\tvalidation_0-logloss:0.136136\n",
      "[48]\tvalidation_0-logloss:0.135971\n",
      "[49]\tvalidation_0-logloss:0.135851\n",
      "[50]\tvalidation_0-logloss:0.135712\n",
      "[51]\tvalidation_0-logloss:0.13561\n",
      "[52]\tvalidation_0-logloss:0.135537\n",
      "[53]\tvalidation_0-logloss:0.135438\n",
      "[54]\tvalidation_0-logloss:0.135337\n",
      "[55]\tvalidation_0-logloss:0.135282\n",
      "[56]\tvalidation_0-logloss:0.135221\n",
      "[57]\tvalidation_0-logloss:0.135194\n",
      "[58]\tvalidation_0-logloss:0.135145\n",
      "[59]\tvalidation_0-logloss:0.135083\n",
      "[60]\tvalidation_0-logloss:0.135061\n",
      "[61]\tvalidation_0-logloss:0.135024\n",
      "[62]\tvalidation_0-logloss:0.134996\n",
      "[63]\tvalidation_0-logloss:0.134975\n",
      "[64]\tvalidation_0-logloss:0.134963\n",
      "[65]\tvalidation_0-logloss:0.134938\n",
      "[66]\tvalidation_0-logloss:0.134948\n",
      "[67]\tvalidation_0-logloss:0.134937\n",
      "[68]\tvalidation_0-logloss:0.134919\n",
      "[69]\tvalidation_0-logloss:0.134929\n",
      "[70]\tvalidation_0-logloss:0.134919\n",
      "[71]\tvalidation_0-logloss:0.134886\n",
      "[72]\tvalidation_0-logloss:0.134872\n",
      "[73]\tvalidation_0-logloss:0.134886\n",
      "[74]\tvalidation_0-logloss:0.134893\n",
      "[75]\tvalidation_0-logloss:0.134891\n",
      "[76]\tvalidation_0-logloss:0.134878\n",
      "[77]\tvalidation_0-logloss:0.134876\n",
      "[78]\tvalidation_0-logloss:0.134878\n",
      "[79]\tvalidation_0-logloss:0.134865\n",
      "[80]\tvalidation_0-logloss:0.134863\n",
      "[81]\tvalidation_0-logloss:0.134873\n",
      "[82]\tvalidation_0-logloss:0.134861\n",
      "[83]\tvalidation_0-logloss:0.134881\n",
      "[84]\tvalidation_0-logloss:0.134869\n",
      "[85]\tvalidation_0-logloss:0.134887\n",
      "[86]\tvalidation_0-logloss:0.134886\n",
      "[87]\tvalidation_0-logloss:0.13489\n",
      "[88]\tvalidation_0-logloss:0.134893\n",
      "[89]\tvalidation_0-logloss:0.134864\n",
      "[90]\tvalidation_0-logloss:0.134878\n",
      "[91]\tvalidation_0-logloss:0.13487\n",
      "[92]\tvalidation_0-logloss:0.134872\n",
      "Stopping. Best iteration:\n",
      "[82]\tvalidation_0-logloss:0.134861\n",
      "\n",
      "Valid accuracy: 0.961325342078\n",
      "build user:837533, valid user:44363\n",
      "FINAL SHAPE\n",
      "x_train.shape:(837533, 651)\n",
      "x_val.shape:(44363, 651)\n",
      "[0]\tvalidation_0-logloss:0.684607\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.676238\n",
      "[2]\tvalidation_0-logloss:0.668033\n",
      "[3]\tvalidation_0-logloss:0.659987\n",
      "[4]\tvalidation_0-logloss:0.652096\n",
      "[5]\tvalidation_0-logloss:0.644357\n",
      "[6]\tvalidation_0-logloss:0.636764\n",
      "[7]\tvalidation_0-logloss:0.629315\n",
      "[8]\tvalidation_0-logloss:0.622003\n",
      "[9]\tvalidation_0-logloss:0.614828\n",
      "[10]\tvalidation_0-logloss:0.607785\n",
      "[11]\tvalidation_0-logloss:0.600869\n",
      "[12]\tvalidation_0-logloss:0.594081\n",
      "[13]\tvalidation_0-logloss:0.587413\n",
      "[14]\tvalidation_0-logloss:0.580865\n",
      "[15]\tvalidation_0-logloss:0.574435\n",
      "[16]\tvalidation_0-logloss:0.568117\n",
      "[17]\tvalidation_0-logloss:0.561909\n",
      "[18]\tvalidation_0-logloss:0.555811\n",
      "[19]\tvalidation_0-logloss:0.549818\n",
      "[20]\tvalidation_0-logloss:0.543928\n",
      "[21]\tvalidation_0-logloss:0.538139\n",
      "[22]\tvalidation_0-logloss:0.532448\n",
      "[23]\tvalidation_0-logloss:0.526854\n",
      "[24]\tvalidation_0-logloss:0.521354\n",
      "[25]\tvalidation_0-logloss:0.515944\n",
      "[26]\tvalidation_0-logloss:0.510627\n",
      "[27]\tvalidation_0-logloss:0.505396\n",
      "[28]\tvalidation_0-logloss:0.500251\n",
      "[29]\tvalidation_0-logloss:0.49519\n",
      "[30]\tvalidation_0-logloss:0.490213\n",
      "[31]\tvalidation_0-logloss:0.485316\n",
      "[32]\tvalidation_0-logloss:0.480497\n",
      "[33]\tvalidation_0-logloss:0.475755\n",
      "[34]\tvalidation_0-logloss:0.471089\n",
      "[35]\tvalidation_0-logloss:0.466498\n",
      "[36]\tvalidation_0-logloss:0.461979\n",
      "[37]\tvalidation_0-logloss:0.457532\n",
      "[38]\tvalidation_0-logloss:0.453153\n",
      "[39]\tvalidation_0-logloss:0.448844\n",
      "[40]\tvalidation_0-logloss:0.444604\n",
      "[41]\tvalidation_0-logloss:0.440429\n",
      "[42]\tvalidation_0-logloss:0.436315\n",
      "[43]\tvalidation_0-logloss:0.432267\n",
      "[44]\tvalidation_0-logloss:0.42828\n",
      "[45]\tvalidation_0-logloss:0.424354\n",
      "[46]\tvalidation_0-logloss:0.420486\n",
      "[47]\tvalidation_0-logloss:0.416679\n",
      "[48]\tvalidation_0-logloss:0.412925\n",
      "[49]\tvalidation_0-logloss:0.409226\n",
      "[50]\tvalidation_0-logloss:0.40558\n",
      "[51]\tvalidation_0-logloss:0.401991\n",
      "[52]\tvalidation_0-logloss:0.398455\n",
      "[53]\tvalidation_0-logloss:0.394969\n",
      "[54]\tvalidation_0-logloss:0.391538\n",
      "[55]\tvalidation_0-logloss:0.388156\n",
      "[56]\tvalidation_0-logloss:0.384824\n",
      "[57]\tvalidation_0-logloss:0.381539\n",
      "[58]\tvalidation_0-logloss:0.378301\n",
      "[59]\tvalidation_0-logloss:0.375111\n",
      "[60]\tvalidation_0-logloss:0.371969\n",
      "[61]\tvalidation_0-logloss:0.36887\n",
      "[62]\tvalidation_0-logloss:0.365816\n",
      "[63]\tvalidation_0-logloss:0.362806\n",
      "[64]\tvalidation_0-logloss:0.359839\n",
      "[65]\tvalidation_0-logloss:0.356915\n",
      "[66]\tvalidation_0-logloss:0.354033\n",
      "[67]\tvalidation_0-logloss:0.351191\n",
      "[68]\tvalidation_0-logloss:0.34839\n",
      "[69]\tvalidation_0-logloss:0.345626\n",
      "[70]\tvalidation_0-logloss:0.342904\n",
      "[71]\tvalidation_0-logloss:0.340217\n",
      "[72]\tvalidation_0-logloss:0.337568\n",
      "[73]\tvalidation_0-logloss:0.334957\n",
      "[74]\tvalidation_0-logloss:0.332384\n",
      "[75]\tvalidation_0-logloss:0.32984\n",
      "[76]\tvalidation_0-logloss:0.327333\n",
      "[77]\tvalidation_0-logloss:0.324859\n",
      "[78]\tvalidation_0-logloss:0.322423\n",
      "[79]\tvalidation_0-logloss:0.320019\n",
      "[80]\tvalidation_0-logloss:0.317649\n",
      "[81]\tvalidation_0-logloss:0.315312\n",
      "[82]\tvalidation_0-logloss:0.313004\n",
      "[83]\tvalidation_0-logloss:0.310731\n",
      "[84]\tvalidation_0-logloss:0.308487\n",
      "[85]\tvalidation_0-logloss:0.306275\n",
      "[86]\tvalidation_0-logloss:0.30409\n",
      "[87]\tvalidation_0-logloss:0.301939\n",
      "[88]\tvalidation_0-logloss:0.299815\n",
      "[89]\tvalidation_0-logloss:0.297721\n",
      "[90]\tvalidation_0-logloss:0.295655\n",
      "[91]\tvalidation_0-logloss:0.293615\n",
      "[92]\tvalidation_0-logloss:0.291603\n",
      "[93]\tvalidation_0-logloss:0.289619\n",
      "[94]\tvalidation_0-logloss:0.287663\n",
      "[95]\tvalidation_0-logloss:0.285731\n",
      "[96]\tvalidation_0-logloss:0.283827\n",
      "[97]\tvalidation_0-logloss:0.281947\n",
      "[98]\tvalidation_0-logloss:0.280092\n",
      "[99]\tvalidation_0-logloss:0.278264\n",
      "Valid accuracy: 0.95949327142\n",
      "build user:837559, valid user:44337\n",
      "FINAL SHAPE\n",
      "x_train.shape:(837559, 651)\n",
      "x_val.shape:(44337, 651)\n",
      "[0]\tvalidation_0-logloss:0.684611\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.676244\n",
      "[2]\tvalidation_0-logloss:0.668041\n",
      "[3]\tvalidation_0-logloss:0.659997\n",
      "[4]\tvalidation_0-logloss:0.65211\n",
      "[5]\tvalidation_0-logloss:0.644373\n",
      "[6]\tvalidation_0-logloss:0.636784\n",
      "[7]\tvalidation_0-logloss:0.629339\n",
      "[8]\tvalidation_0-logloss:0.622032\n",
      "[9]\tvalidation_0-logloss:0.61486\n",
      "[10]\tvalidation_0-logloss:0.607821\n",
      "[11]\tvalidation_0-logloss:0.60091\n",
      "[12]\tvalidation_0-logloss:0.594126\n",
      "[13]\tvalidation_0-logloss:0.587463\n",
      "[14]\tvalidation_0-logloss:0.580919\n",
      "[15]\tvalidation_0-logloss:0.574492\n",
      "[16]\tvalidation_0-logloss:0.56818\n",
      "[17]\tvalidation_0-logloss:0.561976\n",
      "[18]\tvalidation_0-logloss:0.555881\n",
      "[19]\tvalidation_0-logloss:0.549891\n",
      "[20]\tvalidation_0-logloss:0.544006\n",
      "[21]\tvalidation_0-logloss:0.53822\n",
      "[22]\tvalidation_0-logloss:0.532534\n",
      "[23]\tvalidation_0-logloss:0.526943\n",
      "[24]\tvalidation_0-logloss:0.52145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\tvalidation_0-logloss:0.516045\n",
      "[26]\tvalidation_0-logloss:0.510729\n",
      "[27]\tvalidation_0-logloss:0.505507\n",
      "[28]\tvalidation_0-logloss:0.500366\n",
      "[29]\tvalidation_0-logloss:0.495311\n",
      "[30]\tvalidation_0-logloss:0.490336\n",
      "[31]\tvalidation_0-logloss:0.485444\n",
      "[32]\tvalidation_0-logloss:0.480629\n",
      "[33]\tvalidation_0-logloss:0.475894\n",
      "[34]\tvalidation_0-logloss:0.471234\n",
      "[35]\tvalidation_0-logloss:0.466646\n",
      "[36]\tvalidation_0-logloss:0.462131\n",
      "[37]\tvalidation_0-logloss:0.457686\n",
      "[38]\tvalidation_0-logloss:0.453314\n",
      "[39]\tvalidation_0-logloss:0.449008\n",
      "[40]\tvalidation_0-logloss:0.444768\n",
      "[41]\tvalidation_0-logloss:0.440594\n",
      "[42]\tvalidation_0-logloss:0.436486\n",
      "[43]\tvalidation_0-logloss:0.43244\n",
      "[44]\tvalidation_0-logloss:0.428458\n",
      "[45]\tvalidation_0-logloss:0.424533\n",
      "[46]\tvalidation_0-logloss:0.420668\n",
      "[47]\tvalidation_0-logloss:0.41686\n",
      "[48]\tvalidation_0-logloss:0.413107\n",
      "[49]\tvalidation_0-logloss:0.409413\n",
      "[50]\tvalidation_0-logloss:0.405776\n",
      "[51]\tvalidation_0-logloss:0.40219\n",
      "[52]\tvalidation_0-logloss:0.398658\n",
      "[53]\tvalidation_0-logloss:0.395181\n",
      "[54]\tvalidation_0-logloss:0.391753\n",
      "[55]\tvalidation_0-logloss:0.388375\n",
      "[56]\tvalidation_0-logloss:0.385049\n",
      "[57]\tvalidation_0-logloss:0.381766\n",
      "[58]\tvalidation_0-logloss:0.378534\n",
      "[59]\tvalidation_0-logloss:0.375351\n",
      "[60]\tvalidation_0-logloss:0.372211\n",
      "[61]\tvalidation_0-logloss:0.369121\n",
      "[62]\tvalidation_0-logloss:0.366071\n",
      "[63]\tvalidation_0-logloss:0.363062\n",
      "[64]\tvalidation_0-logloss:0.3601\n",
      "[65]\tvalidation_0-logloss:0.357181\n",
      "[66]\tvalidation_0-logloss:0.354303\n",
      "[67]\tvalidation_0-logloss:0.351464\n",
      "[68]\tvalidation_0-logloss:0.348668\n",
      "[69]\tvalidation_0-logloss:0.345911\n",
      "[70]\tvalidation_0-logloss:0.343194\n",
      "[71]\tvalidation_0-logloss:0.340515\n",
      "[72]\tvalidation_0-logloss:0.337873\n",
      "[73]\tvalidation_0-logloss:0.335265\n",
      "[74]\tvalidation_0-logloss:0.332694\n",
      "[75]\tvalidation_0-logloss:0.330156\n",
      "[76]\tvalidation_0-logloss:0.327657\n",
      "[77]\tvalidation_0-logloss:0.32519\n",
      "[78]\tvalidation_0-logloss:0.322761\n",
      "[79]\tvalidation_0-logloss:0.320362\n",
      "[80]\tvalidation_0-logloss:0.317997\n",
      "[81]\tvalidation_0-logloss:0.315667\n",
      "[82]\tvalidation_0-logloss:0.313368\n",
      "[83]\tvalidation_0-logloss:0.311099\n",
      "[84]\tvalidation_0-logloss:0.308864\n",
      "[85]\tvalidation_0-logloss:0.306658\n",
      "[86]\tvalidation_0-logloss:0.304483\n",
      "[87]\tvalidation_0-logloss:0.302336\n",
      "[88]\tvalidation_0-logloss:0.30022\n",
      "[89]\tvalidation_0-logloss:0.298132\n",
      "[90]\tvalidation_0-logloss:0.296073\n",
      "[91]\tvalidation_0-logloss:0.294042\n",
      "[92]\tvalidation_0-logloss:0.292038\n",
      "[93]\tvalidation_0-logloss:0.290063\n",
      "[94]\tvalidation_0-logloss:0.288113\n",
      "[95]\tvalidation_0-logloss:0.28619\n",
      "[96]\tvalidation_0-logloss:0.284292\n",
      "[97]\tvalidation_0-logloss:0.282422\n",
      "[98]\tvalidation_0-logloss:0.280574\n",
      "[99]\tvalidation_0-logloss:0.278754\n",
      "Valid accuracy: 0.959401853982\n",
      "build user:837999, valid user:43897\n",
      "FINAL SHAPE\n",
      "x_train.shape:(837999, 651)\n",
      "x_val.shape:(43897, 651)\n",
      "[0]\tvalidation_0-logloss:0.611217\n",
      "Will train until validation_0-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-logloss:0.544178\n",
      "[2]\tvalidation_0-logloss:0.488438\n",
      "[3]\tvalidation_0-logloss:0.441513\n",
      "[4]\tvalidation_0-logloss:0.401622\n",
      "[5]\tvalidation_0-logloss:0.367518\n",
      "[6]\tvalidation_0-logloss:0.338173\n",
      "[7]\tvalidation_0-logloss:0.312727\n",
      "[8]\tvalidation_0-logloss:0.290554\n",
      "[9]\tvalidation_0-logloss:0.271269\n",
      "[10]\tvalidation_0-logloss:0.254513\n",
      "[11]\tvalidation_0-logloss:0.239728\n",
      "[12]\tvalidation_0-logloss:0.226777\n",
      "[13]\tvalidation_0-logloss:0.215451\n",
      "[14]\tvalidation_0-logloss:0.205463\n",
      "[15]\tvalidation_0-logloss:0.196666\n",
      "[16]\tvalidation_0-logloss:0.188906\n",
      "[17]\tvalidation_0-logloss:0.182073\n",
      "[18]\tvalidation_0-logloss:0.176112\n",
      "[19]\tvalidation_0-logloss:0.170869\n",
      "[20]\tvalidation_0-logloss:0.166209\n",
      "[21]\tvalidation_0-logloss:0.16211\n",
      "[22]\tvalidation_0-logloss:0.158471\n",
      "[23]\tvalidation_0-logloss:0.155323\n",
      "[24]\tvalidation_0-logloss:0.152539\n",
      "[25]\tvalidation_0-logloss:0.150109\n",
      "[26]\tvalidation_0-logloss:0.147976\n",
      "[27]\tvalidation_0-logloss:0.146122\n",
      "[28]\tvalidation_0-logloss:0.144458\n",
      "[29]\tvalidation_0-logloss:0.143057\n",
      "[30]\tvalidation_0-logloss:0.141779\n",
      "[31]\tvalidation_0-logloss:0.14064\n",
      "[32]\tvalidation_0-logloss:0.139661\n",
      "[33]\tvalidation_0-logloss:0.138805\n",
      "[34]\tvalidation_0-logloss:0.138084\n",
      "[35]\tvalidation_0-logloss:0.137483\n",
      "[36]\tvalidation_0-logloss:0.136959\n",
      "[37]\tvalidation_0-logloss:0.136477\n",
      "[38]\tvalidation_0-logloss:0.136036\n",
      "[39]\tvalidation_0-logloss:0.135652\n",
      "[40]\tvalidation_0-logloss:0.135356\n",
      "[41]\tvalidation_0-logloss:0.135094\n",
      "[42]\tvalidation_0-logloss:0.134888\n",
      "[43]\tvalidation_0-logloss:0.134694\n",
      "[44]\tvalidation_0-logloss:0.134484\n",
      "[45]\tvalidation_0-logloss:0.134342\n",
      "[46]\tvalidation_0-logloss:0.134203\n",
      "[47]\tvalidation_0-logloss:0.134052\n",
      "[48]\tvalidation_0-logloss:0.133942\n",
      "[49]\tvalidation_0-logloss:0.133838\n",
      "[50]\tvalidation_0-logloss:0.133789\n",
      "[51]\tvalidation_0-logloss:0.133696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "models = [] # for the following prediction(test)\n",
    "paras = []\n",
    "md = [6,10,20] # max_depth\n",
    "lr = [0.1, 0.01, 0.01] # learning_rate\n",
    "mcw = [20,25,30] # min_child_weight: The larger, the more conservative the algorithm will be.\n",
    "for m in md:\n",
    "    for l in lr:\n",
    "        #for n in mcw:\n",
    "        # split data in train/valid\n",
    "        x_train, y_train, x_val, y_val = split_build_valid(valid_size = 0.05)\n",
    "        print ('y_train',y_train.describe().ix['mean'])\n",
    "        print ('y_val',y_val.describe().ix['mean'])\n",
    "        model = XGBClassifier(objective = 'binary:logistic',\n",
    "                              max_depth = m, learning_rate = l,\n",
    "                              seed = 72\n",
    "                             )\n",
    "        model.fit(x_train, y_train, \n",
    "                  eval_metric ='logloss' , eval_set = [(x_val,y_val)],\n",
    "                  early_stopping_rounds = 10) \n",
    "        #print('fature importance',model.feature_importances_)\n",
    "        # validating\n",
    "        valid_ypred = model.predict(x_val) # y_hat is result of prediction\n",
    "        predictions = [round(value) for value in valid_ypred]\n",
    "        accuracy = accuracy_score(y_val, predictions)\n",
    "        print('Valid accuracy:', accuracy)\n",
    "        # for pircking the best parameters from validating result\n",
    "        para = {}\n",
    "        para['max_depth'] = m\n",
    "        para['learning_rate'] = l\n",
    "        para['min_child_weight'] = n\n",
    "        paras.append((para,accuracy))\n",
    "        models.append(model)\n",
    "'''\n",
    "Here are some steps I suggest you follow:\n",
    "\n",
    "1.Make it more than 10 iterations before stopping.(early_stopping_rounds = 10)\n",
    "2.Lower the eta-value.(learning_rate)\n",
    "3.Increase the max depth.\n",
    "References: https://www.kaggle.com/karelrv/nyct-from-a-to-z-with-xgboost-tutorial\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e3f5417d5d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_para_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_para\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_para_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_para\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'paras' is not defined"
     ]
    }
   ],
   "source": [
    "best_para_index = [p[1] for p in paras].index(max([p[1] for p in paras]))\n",
    "best_para = paras[best_para_index]\n",
    "best_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 20},\n",
       "  0.93714285714285717),\n",
       " ({'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 25},\n",
       "  0.94244604316546765),\n",
       " ({'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 30},\n",
       "  0.93548387096774188),\n",
       " ({'learning_rate': 0.3, 'max_depth': 6, 'min_child_weight': 20},\n",
       "  0.95483870967741935),\n",
       " ({'learning_rate': 0.3, 'max_depth': 6, 'min_child_weight': 25},\n",
       "  0.9640718562874252),\n",
       " ({'learning_rate': 0.3, 'max_depth': 6, 'min_child_weight': 30},\n",
       "  0.9513513513513514)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras \n",
    "'''\n",
    "In summary:\n",
    "1. when fixed learning rate, we found it's the best scenario when min_child_weight = 25\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid SearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reference: https://github.com/ParrotPrediction/docker-course-xgboost/blob/master/notebooks/3.%20Going%20deeper/3.3%20Hyper-parameter%20tuning.ipynb\n",
    "Q1:Can we run Grid SearchCV for very small sample of data to find optimal paras?\n",
    "No, Cause max_depth and n_estimators are related to the amount of data\n",
    "'''\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold # for stratified cv\n",
    "from scipy.stats import randint, uniform # for randomizedSerchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic', 'silent': 0}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_fixed = {'objective' : 'binary:logistic',\n",
    "               'silent' : 0}\n",
    "params_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunning parameters\n",
    "params_grid = {\n",
    "    'max_depth': [1, 2, 3],\n",
    "    'n_estimators': [5, 10, 25, 50],\n",
    "    'learning_rate': np.linspace(1e-16, 1, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.values[:,1:]\n",
    "y = Y_train.values\n",
    "# Define cross-validation strategy for testing. \n",
    "# Let's use StratifiedKFold which guarantees that target label is equally distributed across each fold:\n",
    "cv = StratifiedKFold(y, n_folds=5, shuffle=True, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 651)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSearchCV estimator. We will be looking for combination giving the best accuracy.\n",
    "bst_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(**params_fixed, seed=72),\n",
    "    param_grid=params_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[0 0 ..., 0 0], n_folds=5, shuffle=True, random_state=72),\n",
       "       error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=72, silent=0,\n",
       "       subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 2, 3], 'n_estimators': [5, 10, 25, 50], 'learning_rate': array([  1.00000e-16,   5.00000e-01,   1.00000e+00])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Before running the calculations notice that 3*4*3*5(n_folds)=180 models will be created to test all combinations. \n",
    "You should always have rough estimations about what is going to happen.\n",
    "'''\n",
    "# running\n",
    "bst_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 1, 'n_estimators': 5},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 1, 'n_estimators': 10},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 1, 'n_estimators': 25},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 1, 'n_estimators': 50},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 2, 'n_estimators': 5},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 2, 'n_estimators': 10},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 2, 'n_estimators': 25},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 2, 'n_estimators': 50},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 3, 'n_estimators': 5},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 3, 'n_estimators': 10},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 3, 'n_estimators': 25},\n",
       " mean: 0.93833, std: 0.00000, params: {'learning_rate': 9.9999999999999998e-17, 'max_depth': 3, 'n_estimators': 50},\n",
       " mean: 0.94467, std: 0.00125, params: {'learning_rate': 0.5, 'max_depth': 1, 'n_estimators': 5},\n",
       " mean: 0.94533, std: 0.00245, params: {'learning_rate': 0.5, 'max_depth': 1, 'n_estimators': 10},\n",
       " mean: 0.94700, std: 0.00452, params: {'learning_rate': 0.5, 'max_depth': 1, 'n_estimators': 25},\n",
       " mean: 0.94733, std: 0.00533, params: {'learning_rate': 0.5, 'max_depth': 1, 'n_estimators': 50},\n",
       " mean: 0.94800, std: 0.00627, params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 5},\n",
       " mean: 0.94700, std: 0.00572, params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 10},\n",
       " mean: 0.94700, std: 0.00542, params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 25},\n",
       " mean: 0.94700, std: 0.00609, params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 50},\n",
       " mean: 0.95100, std: 0.00750, params: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 5},\n",
       " mean: 0.94900, std: 0.00779, params: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 10},\n",
       " mean: 0.94867, std: 0.00591, params: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 25},\n",
       " mean: 0.94967, std: 0.00678, params: {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 50},\n",
       " mean: 0.94733, std: 0.00170, params: {'learning_rate': 1.0, 'max_depth': 1, 'n_estimators': 5},\n",
       " mean: 0.94233, std: 0.00271, params: {'learning_rate': 1.0, 'max_depth': 1, 'n_estimators': 10},\n",
       " mean: 0.94367, std: 0.00488, params: {'learning_rate': 1.0, 'max_depth': 1, 'n_estimators': 25},\n",
       " mean: 0.94100, std: 0.00467, params: {'learning_rate': 1.0, 'max_depth': 1, 'n_estimators': 50},\n",
       " mean: 0.94533, std: 0.00452, params: {'learning_rate': 1.0, 'max_depth': 2, 'n_estimators': 5},\n",
       " mean: 0.94267, std: 0.00429, params: {'learning_rate': 1.0, 'max_depth': 2, 'n_estimators': 10},\n",
       " mean: 0.94200, std: 0.00718, params: {'learning_rate': 1.0, 'max_depth': 2, 'n_estimators': 25},\n",
       " mean: 0.94233, std: 0.00501, params: {'learning_rate': 1.0, 'max_depth': 2, 'n_estimators': 50},\n",
       " mean: 0.94100, std: 0.00663, params: {'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 5},\n",
       " mean: 0.93900, std: 0.00827, params: {'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 10},\n",
       " mean: 0.94267, std: 0.00602, params: {'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 25},\n",
       " mean: 0.94333, std: 0.00471, params: {'learning_rate': 1.0, 'max_depth': 3, 'n_estimators': 50}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can look at all obtained scores, and try to manually see what matters and what not.\n",
    "bst_grid.grid_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy obtained: 0.951\n",
      "Parameters:\n",
      "\tlearning_rate: 0.5\n",
      "\tmax_depth: 3\n",
      "\tn_estimators: 5\n"
     ]
    }
   ],
   "source": [
    "# If there are many results, we can filter them manually to get the best combination\n",
    "\n",
    "print(\"Best accuracy obtained: {0}\".format(bst_grid.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for key, value in bst_grid.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f45cf22b1b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m train_scores, test_scores = validation_curve(\n\u001b[1;32m     33\u001b[0m     \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mparam_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mparam_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_estimators_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.learning_curve import validation_curve # Determine training and test scores for varying parameter values.\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from scipy.sparse import vstack\n",
    "'''\n",
    "Operation procedure:\n",
    "1. fixed learning_rate =0.1\n",
    "2. using cross-validation fisrt to find optimal number of trees\n",
    "    the following tree-based parameters are default value. Later on, we need to tune this parameters.\n",
    "    -max_depth = 6\n",
    "    -min_child_weight = 1\n",
    "    -gamma = 0\n",
    "    -subsample, colsample_bytree = 0.8 \n",
    "    -scale_pos_weight = 1\n",
    "'''\n",
    "\n",
    "default_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma' : 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'silent': 1.0\n",
    "}\n",
    "# prepare X,y\n",
    "print (X_train.shape)\n",
    "print (Y_train.shape)\n",
    "\n",
    "#We will divide into 10 stratified folds (the same distibution of labels in each fold) for testing\n",
    "cv = StratifiedKFold(Y_train, n_folds=10, shuffle=True, random_state=seed)\n",
    "\n",
    "#Return evenly spaced numbers over a specified interval.\n",
    "n_estimators_range = np.linspace(start = 1, stop = 1000, num = 50).astype('int') \n",
    "\n",
    "# tuning n_estimators\n",
    "train_scores, test_scores = validation_curve(\n",
    "    XGBClassifier(**default_params),\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    param_name = 'n_estimators',\n",
    "    param_range = n_estimators_range,\n",
    "    cv=cv,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "print (n_estimators_range)\n",
    "# \n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "# plot\n",
    "plt.title(\"Validation Curve with XGBoost (eta = 0.3)\")\n",
    "plt.xlabel(\"number of trees\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.7, 1.1)\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             train_scores_mean,\n",
    "             label=\"Training score\",\n",
    "             color=\"r\")\n",
    "\n",
    "plt.plot(n_estimators_range,\n",
    "             test_scores_mean, \n",
    "             label=\"Cross-validation score\",\n",
    "             color=\"g\")\n",
    "\n",
    "plt.fill_between(n_estimators_range, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, \n",
    "                 alpha=0.2, color=\"r\")\n",
    "\n",
    "plt.fill_between(n_estimators_range,\n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std,\n",
    "                 alpha=0.2, color=\"g\")\n",
    "\n",
    "plt.axhline(y=1, color='k', ls='dashed')\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "i = np.argmax(test_scores_mean) # best index\n",
    "\n",
    "'''\n",
    "Looking at the plot we can draw the following conclusions:\n",
    "\n",
    "1.training score keeps growing while adding new trees, but from a certain point CV score is fixed\n",
    "2. variance is lowest, and bias is high for less than 25 trees,\n",
    "3.from about 25 trees, the variance is getting higher and while the CV score bias is holding steady (there is no point for adding extra trees / complexity)\n",
    "we can see that the model is quite stable keeping variance fixed when increasing it's complexity\n",
    "4.We can assume that the trade-off for our model will be met at n_estimators = 50. The variance is still to big.\n",
    "'''\n",
    "print(\"Best cross-validation result ({0:.2f}) obtained for {1} trees\".format(test_scores_mean[i], n_estimators_range[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"xgboost python api:http://xgboost.readthedocs.io/en/latest/python/python_api.html\"\n",
    "\"\"\"\n",
    "德全:https://github.com/stuser/temp/blob/master/kaggle_intro/kaggle_intro_iris2.ipynb\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
